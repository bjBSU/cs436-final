{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Classification - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT fine-tuning for document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.4)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "since the target is the names we will split the data by bird names (y) and the rest of the features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the TXT file into a DataFrame\n",
    "df = pd.read_csv(\"Bird_Data.txt\", delimiter=\",\", header=0)  # Adjust the delimiter based on your file format\n",
    "\n",
    "df.rename(columns={ #rename the columns to be more consice\n",
    "    \"Frequency %\": \"Frequency\",\n",
    "    \"Size (Max) in\": \"Size\",\n",
    "    \"Weight (Max) g\": \"Weight\"\n",
    "}, inplace=True)\n",
    "\n",
    "df.fillna(\"Unknown\", inplace=True)  # Replace NaN with 'Unknown'\n",
    "#df.dropna(inplace=True) #drop rows with missing data\n",
    "\n",
    "# Assign X and Y values\n",
    "X = df[['Frequency', 'Colors', 'Size', 'Weight', 'Genus', 'Family', 'Description']]  # Feature columns\n",
    "y = df['Names']  # Target column\n",
    "\n",
    "# Optionally save the X and Y values into separate files\n",
    "X.to_csv(\"X_values.csv\", index=False)\n",
    "y.to_csv(\"Y_values.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 99)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for validation testing\n",
    "prompt = pd.read_csv(\"prompt_eng.csv\", header=0)\n",
    "X_prompt = prompt['sentence_description']         # descriptions to feed into model\n",
    "Y_prompt = prompt['desired_bird']                  # actual correct bird name\n",
    "#test_y_prompt = np.array(X_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An easy train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70, 29, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beth - 4/15/25: Proposing we update split to something more like 70 to 30, I think the previous\n",
    "# method it was overlapping since output was (90, 90, 89, 89)\n",
    "\n",
    "# Beth's Proposed Code:\n",
    "train_X = X[:70]\n",
    "train_y = np.array(y[:70])\n",
    "test_X = X[70:] # Captures 29%\n",
    "test_y = np.array(y[70:]) # Captures 29%\n",
    "\n",
    "len(train_X), len(train_y), len(test_X), len(test_y)\n",
    "\n",
    "#Output: (70, 70, 29, 29) ensures no overlapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not needed for training or evaluation, but useful for mapping examples\n",
    "labels = {\n",
    "    0:'Names',\n",
    "    1:'Frequency',\n",
    "    2:'Colors',\n",
    "    3:'Size',\n",
    "    4:'Weight',\n",
    "    5:'Genus',\n",
    "    6:'Family',\n",
    "    7:'Description'\n",
    "}\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune BERT on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Project language fine-tuning*\n",
    "\n",
    "*loss function needs to change* \n",
    "\n",
    "*num-out needs to change*\n",
    "\n",
    "*Not a binary task so this means we will need to use something like cross enropy - torch uses index values*\n",
    "\n",
    "*try to get around 80% on the test set*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.targets = labels\n",
    "        self.targets = torch.tensor(labels, dtype=torch.long)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            padding = 'max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            \n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets' : self.targets[index]\n",
    "            #.clone().detach()\n",
    "            #'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Class\n",
    "- first \"layer\" is a pre-trained BERT model\n",
    "- you can add whatever layers you want after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, NUM_OUT):\n",
    "        super(BERTClass, self).__init__()\n",
    "\n",
    "        # Get the Bert Model that is pretrained\n",
    "        # self.l1 = BertModel.from_pretrained(\"bert-base-uncased\")#bert-base-uncased and BertModel\n",
    "        self.l1 = BertModel.from_pretrained(\"prajjwal1/bert-mini\")\n",
    "\n",
    "        #Pass through the classifier we designed\n",
    "        self.pre_classifier = torch.nn.Linear(self.l1.config.hidden_size, 256)#768\n",
    "        self.classifier = torch.nn.Linear(256, NUM_OUT)#768 or 196\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "        # Apply softmax activation\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        # Beth Fix: 4/21/25 - Need to reduce pooler batch size\n",
    "        reduced_pooler = self.pre_classifier(pooler)\n",
    "        output = self.classifier(reduced_pooler)\n",
    "        # output = self.classifier(pooler)\n",
    "        output = self.softmax(output) # Beth - Should not be used with CrossEntropyloss\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful functions:\n",
    "### Loss\n",
    "- This task is binary, so it uses binary crossentropy loss\n",
    "- Tasks with more labels will use categorical crossentropy\n",
    "- Tasks that don't have labels, but rather have distributions should use KL divergence\n",
    "- Tasks that don't have distributions should use something like RMSE loss\n",
    "### Train\n",
    "- Steps through the data batch by batch\n",
    "- grabs ids, masks, and token_type_ids which are required inputs for BERT\n",
    "- inputs are passed through the model, compared to targets, computes loss function, backprops\n",
    "### Validation\n",
    "- Takes a model, passes inputs\n",
    "- Need to use the targets from here because they are potentially shuffled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function - Uses Categorical Cross Entropy instead of Binary Entropy\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "# Train Function - Step through data batch by batch\n",
    "def train(model, training_loader, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    for data in tqdm(training_loader):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad() # Beth: Removing duplicate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss\n",
    "\n",
    "# Validation Function - Take Model Pass Inputs\n",
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testing_loader):\n",
    "            targets = data['targets']\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            #outputs = torch.sigmoid(outputs).cpu().detach()\n",
    "            outputs = torch.argmax(outputs, dim=1).cpu().detach()\n",
    "            fin_outputs.extend(outputs.tolist())\n",
    "            fin_targets.extend(targets.tolist())\n",
    "    return torch.tensor(fin_outputs), torch.tensor(fin_targets)\n",
    "\n",
    "# Gets top 3 results Function - Take Model Pass Inputs\n",
    "def validation_top3(model, testing_loader, le):\n",
    "    model.eval()  # Ensure model is in evaluation mode\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        for data in tqdm(testing_loader):\n",
    "            targets = data['targets']  # True labels (bird names or IDs)\n",
    "            ids = data['ids'].to(device, dtype=torch.long)\n",
    "            mask = data['mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        \n",
    "            outputs = model(ids, mask, token_type_ids)  # Model's outputs (batch_size, num_classes)\n",
    "\n",
    "            # Get top 3 predictions for each sample\n",
    "            top3_vals, top3_indices = torch.topk(outputs, k=3, dim=1)  # (batch_size, 3)\n",
    "\n",
    "            # Map top 3 indices to bird names using label encoder\n",
    "            top3_names_batch = []\n",
    "            for indices in top3_indices.cpu().numpy():  # Iterate over each item in the batch\n",
    "                names = le.inverse_transform(indices)  # Convert indices to bird names\n",
    "                top3_names_batch.append(names.tolist())  # Store as a list of 3 names\n",
    "\n",
    "            fin_outputs.extend(top3_names_batch)  # Add the top 3 predictions\n",
    "            fin_targets.extend(targets.tolist())  # Add the ground truth targets\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  4242,   102,  ...,     0,     0,     0],\n",
       "        [  101,  3609,   102,  ...,     0,     0,     0],\n",
       "        [  101,  2227,  1010,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1037,  5810,  ...,     0,     0,     0],\n",
       "        [  101,  1037,  2235,  ...,     0,     0,     0],\n",
       "        [  101,  1037, 20640,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-mini')\n",
    "\n",
    "#Beth - 4/15/25: Convert train to proper data type:\n",
    "desc_list = train_X[\"Description\"].tolist()\n",
    "\n",
    "#Beth - 4/21/25: Trying a different method to encode since we use desc_list so need batch\n",
    "tokenizer.batch_encode_plus(\n",
    "            desc_list, # Beth 4/15/25: replaced train_X[5] with the list version (DF was erroring)\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'              \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(np.concatenate([train_y, test_y]))\n",
    "\n",
    "train_y_encoded = le.transform(train_y)\n",
    "test_y_encoded = le.transform(test_y)\n",
    "\n",
    "train_y_tensor = torch.from_numpy(train_y_encoded).long()\n",
    "test_y_tensor = torch.from_numpy(test_y_encoded).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29361/1357419957.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10  #5.88% for 10 and 50 epochs\n",
    "# Beth Propoal: Shouldn't this be 8?\n",
    "# NUM_OUT = 7 # binary task - 2\n",
    "\n",
    "# Beth - 4/23/25: Trying this instead, may need to focus on the actual bird names\n",
    "NUM_OUT = len(le.classes_)\n",
    "LEARNING_RATE = 2e-05 #2e-05 standard gave 5.88% with 10/50 epoch\n",
    "\n",
    "train_desc_list = train_X[\"Description\"].tolist()\n",
    "test_desc_list = test_X[\"Description\"].tolist()\n",
    "\n",
    "training_data = MultiLabelDataset(train_desc_list, train_y_tensor, tokenizer, MAX_LEN)\n",
    "test_data = MultiLabelDataset(test_desc_list, test_y_tensor, tokenizer, MAX_LEN)\n",
    "\n",
    "\n",
    "train_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }    \n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_data, **train_params)\n",
    "testing_loader = torch.utils.data.DataLoader(test_data, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c5e39acc6b41d28e5f7746b7a6264e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  4.594884395599365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e973fee5e24a35b5e371f2686cd342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ef5e03abd64e12b56930731f2794ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  4.592948913574219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cc47559388462b8326620201f6c8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64abf48fd166445d850e7874a2341c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  4.594738483428955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e8f6ddf1b74714bd064cdf94b89675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e951616832542bcb44d91cf4121a4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  4.592576026916504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177dd3dbdc5e492db0b3a19001fbfddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076ac1087b744fa49c24de059f1d3a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  4.592197895050049\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b27e46e8544c1fb54ec42d223af76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e996f6bbab4175bdb4a2f4bb82c3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  4.594428062438965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55acf3e41caa479e9088ec5d3e62962d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19fde0cd61a4e4ab0780d8308bf8301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  4.591325759887695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8a91ee34f54a3eb32d9cfa06f0610c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6221023f851340d18c82139100dac0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  4.590301990509033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af01095040304a6fa352a2dedf6cc214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809701e97b66485c8a8f6d65a12b0140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss:  4.584939002990723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc82579f506430d9b517e52fd1c2603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39599520550c4d2da7dc163a8f59d005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss:  4.586690425872803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a90ead2ce9342fcb16cd50b53a5304f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arracy on test set 0.0\n"
     ]
    }
   ],
   "source": [
    "#Beth Proposal: When time allows, maybe we should setup something to save our epoch progress\n",
    "\n",
    "model = BERTClass(NUM_OUT)\n",
    "model.to(device)    \n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train(model, training_loader, optimizer)\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')  \n",
    "    guess, targs = validation(model, testing_loader)\n",
    "    guesses = guess\n",
    "    targets = targs\n",
    "    torch.save(model.state_dict(), './model.pt')\n",
    "    print('arracy on test set {}'.format(accuracy_score(guesses.numpy(), targets.numpy())))#.indices\n",
    "    # print(f'Accuracy on test set: {accuracy_score(guess.cpu().numpy(), targs.cpu().numpy())}') # Beth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bird sentences into our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29361/1357419957.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(labels, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7670351d58c34e15acebc16d28953d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['Pileated Woodpecker', 'Western Bluebird', 'California Quail'], ['Western Bluebird', 'Red-breasted Nuthatch', 'Tree Swallow'], ['Bald Eagle', 'Tree Swallow', 'Brown Creeper'], ['Tree Swallow', 'Bald Eagle', \"Swainson's hawk\"], ['Western Bluebird', \"Swainson's hawk\", 'Bald Eagle'], ['Tree Swallow', \"Swainson's hawk\", 'Turkey Vulture'], ['Bald Eagle', 'Belted Kingfisher', 'Western Bluebird'], [\"Swainson's hawk\", 'Tree Swallow', 'Bald Eagle'], ['Bald Eagle', 'Eurasian Collared-Dove', \"Swainson's hawk\"], ['Tree Swallow', \"Swainson's hawk\", 'Bald Eagle'], ['Pileated Woodpecker', \"Swainson's hawk\", 'Bald Eagle'], ['Yellow Warbler', 'Pileated Woodpecker', 'House finch'], ['Bald Eagle', 'Tree Swallow', 'Western Grebe'], ['Bald Eagle', 'Dark-eyed Junco', 'Tree Swallow'], [\"Swainson's hawk\", 'Tree Swallow', 'Pileated Woodpecker'], ['Western Bluebird', 'Belted Kingfisher', 'Bald Eagle'], ['Bald Eagle', 'Tree Swallow', 'Brown Creeper']], [75, 45, 87, 71, 88, 37, 70, 49, 22, 8, 55, 59, 95, 84, 5, 19, 53])\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "Name: score, dtype: int64\n",
      "\n",
      "Accuracy (score == 3): 0.00%\n"
     ]
    }
   ],
   "source": [
    "test_prompt_encoded = le.transform(Y_prompt)\n",
    "test_prompt_tensor = torch.from_numpy(test_prompt_encoded).long()\n",
    "test_data_prompt = MultiLabelDataset(X_prompt, test_prompt_tensor, tokenizer, MAX_LEN)\n",
    "testing_prompt_loader = torch.utils.data.DataLoader(test_data_prompt, **test_params)\n",
    "\n",
    "#new test\n",
    "results = validation_top3(model, testing_prompt_loader, le)\n",
    "print(results)\n",
    "prompt[\"bird_model\"] = [str(names) for names in results[0]] \n",
    "prompt.to_csv(\"prompt_eng.csv\", index=False)\n",
    "\n",
    "# Define a scoring function\n",
    "def score_match(row):\n",
    "    try:\n",
    "        index = row['bird_model'].index(row['desired_bird']) \n",
    "        prompt['bird_model'] = results[0]\n",
    "        return 3 - index  # index 0 = 3 points, index 1 = 2, index 2 = 1\n",
    "    except ValueError:\n",
    "        return 0  # not in list\n",
    "\n",
    "prompt['score'] = prompt.apply(score_match, axis=1)\n",
    "\n",
    "# Calculate accuracy based on score == 3\n",
    "accuracy = (prompt['score'] == 3).mean()\n",
    "\n",
    "# Print results\n",
    "print(prompt['score'])\n",
    "print(f\"\\nAccuracy (score == 3): {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29361/1357419957.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(labels, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82524749ea554d9faa5e2e97defe6ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['Bald Eagle', 'Eurasian Collared-Dove', \"Swainson's hawk\"], ['Bald Eagle', 'Dark-eyed Junco', 'Tree Swallow'], ['Bald Eagle', 'Belted Kingfisher', 'Western Bluebird'], [\"Swainson's hawk\", 'Tree Swallow', 'Pileated Woodpecker'], ['Tree Swallow', 'Bald Eagle', \"Swainson's hawk\"], ['Bald Eagle', 'Tree Swallow', 'Brown Creeper'], ['Bald Eagle', 'Tree Swallow', 'Western Grebe'], ['Western Bluebird', 'Red-breasted Nuthatch', 'Tree Swallow'], ['Pileated Woodpecker', 'Western Bluebird', 'California Quail'], ['Yellow Warbler', 'Pileated Woodpecker', 'House finch'], ['Pileated Woodpecker', \"Swainson's hawk\", 'Bald Eagle'], ['Bald Eagle', 'Tree Swallow', 'Brown Creeper'], ['Tree Swallow', \"Swainson's hawk\", 'Bald Eagle'], ['Western Bluebird', 'Belted Kingfisher', 'Bald Eagle'], [\"Swainson's hawk\", 'Tree Swallow', 'Bald Eagle'], ['Tree Swallow', \"Swainson's hawk\", 'Turkey Vulture'], ['Western Bluebird', \"Swainson's hawk\", 'Bald Eagle']], [22, 84, 70, 5, 71, 53, 95, 45, 75, 59, 55, 87, 8, 19, 49, 37, 88])\n",
      "            desired_bird                                         bird_model  \\\n",
      "0         American Robin  [Bald Eagle, Eurasian Collared-Dove, Swainson'...   \n",
      "1             Bald Eagle        [Bald Eagle, Dark-eyed Junco, Tree Swallow]   \n",
      "2                 Buteos  [Bald Eagle, Belted Kingfisher, Western Bluebird]   \n",
      "3         Prairie falcon  [Swainson's hawk, Tree Swallow, Pileated Woodp...   \n",
      "4          Mourning Dove        [Tree Swallow, Bald Eagle, Swainson's hawk]   \n",
      "5            House Finch          [Bald Eagle, Tree Swallow, Brown Creeper]   \n",
      "6         Turkey Vulture          [Bald Eagle, Tree Swallow, Western Grebe]   \n",
      "7       Western Bluebird  [Western Bluebird, Red-breasted Nuthatch, Tree...   \n",
      "8            Fox sparrow  [Pileated Woodpecker, Western Bluebird, Califo...   \n",
      "9   Red-winged Blackbird  [Yellow Warbler, Pileated Woodpecker, House fi...   \n",
      "10        Spotted Towhee  [Pileated Woodpecker, Swainson's hawk, Bald Ea...   \n",
      "11          Lesser Scaup          [Bald Eagle, Tree Swallow, Brown Creeper]   \n",
      "12         Cedar waxwing        [Tree Swallow, Swainson's hawk, Bald Eagle]   \n",
      "13              Killdeer  [Western Bluebird, Belted Kingfisher, Bald Eagle]   \n",
      "14             Wood Duck        [Swainson's hawk, Tree Swallow, Bald Eagle]   \n",
      "15               Mallard    [Tree Swallow, Swainson's hawk, Turkey Vulture]   \n",
      "16        Pygmy Nuthatch    [Western Bluebird, Swainson's hawk, Bald Eagle]   \n",
      "\n",
      "        top1_prediction  match_rank  score  \n",
      "0            Bald Eagle         NaN      0  \n",
      "1            Bald Eagle         1.0      3  \n",
      "2            Bald Eagle         NaN      0  \n",
      "3       Swainson's hawk         NaN      0  \n",
      "4          Tree Swallow         NaN      0  \n",
      "5            Bald Eagle         NaN      0  \n",
      "6            Bald Eagle         NaN      0  \n",
      "7      Western Bluebird         1.0      3  \n",
      "8   Pileated Woodpecker         NaN      0  \n",
      "9        Yellow Warbler         NaN      0  \n",
      "10  Pileated Woodpecker         NaN      0  \n",
      "11           Bald Eagle         NaN      0  \n",
      "12         Tree Swallow         NaN      0  \n",
      "13     Western Bluebird         NaN      0  \n",
      "14      Swainson's hawk         NaN      0  \n",
      "15         Tree Swallow         NaN      0  \n",
      "16     Western Bluebird         NaN      0  \n",
      "Top-1 Accuracy: 11.76%\n",
      "Top-3 Accuracy: 11.76%\n"
     ]
    }
   ],
   "source": [
    "#  Beth Version of Getting Accuracy Score test\n",
    "import ast\n",
    "\n",
    "def validation_top3_vers2(model, testing_loader, le):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testing_loader):\n",
    "            targets = data['targets']\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            token_type_ids = data['token_type_ids'].to(device)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            top3_vals, top3_indices = torch.topk(outputs, k=3, dim=1)\n",
    "\n",
    "            top3_names_batch = []\n",
    "            for indices in top3_indices.cpu().numpy():\n",
    "                names = [le.classes_[i] for i in indices]\n",
    "                top3_names_batch.append(names)\n",
    "\n",
    "            fin_outputs.extend(top3_names_batch)\n",
    "            fin_targets.extend(targets.tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets\n",
    " \n",
    "\n",
    "test_prompt_encoded = le.transform(Y_prompt)\n",
    "test_prompt_tensor = torch.from_numpy(test_prompt_encoded).long()\n",
    "test_data_prompt = MultiLabelDataset(X_prompt, test_prompt_tensor, tokenizer, MAX_LEN)\n",
    "testing_prompt_loader = torch.utils.data.DataLoader(test_data_prompt, **test_params)\n",
    "\n",
    "#new test\n",
    "results = validation_top3(model, testing_prompt_loader, le)\n",
    "print(results)\n",
    "# Convert string representation of lists into real Python lists\n",
    "prompt['bird_model'] = results[0]  # results[0] contains top-3 predictions\n",
    "prompt.to_csv(\"prompt_eng.csv\", index=False)\n",
    "\n",
    "# Define a scoring function\n",
    "def score_match(row):\n",
    "    try:\n",
    "        index = row['bird_model'].index(row['desired_bird'])\n",
    "        return 3 - index  # index 0 = 3 points, index 1 = 2, index 2 = 1\n",
    "    except ValueError:\n",
    "        return 0  # not in list\n",
    "\n",
    "prompt['score'] = prompt.apply(score_match, axis=1)\n",
    "\n",
    "#for our bird classifier model\n",
    "prompt['top1_prediction'] = prompt['bird_model'].apply(lambda x: x[0])\n",
    "prompt['in_top3'] = prompt.apply(lambda row: row['desired_bird'] in row['bird_model'], axis=1)\n",
    "prompt['match_rank'] = prompt.apply(lambda row: row['bird_model'].index(row['desired_bird']) + 1 if row['desired_bird'] in row['bird_model'] else None, axis=1)\n",
    "\n",
    "print(prompt[['desired_bird', 'bird_model', 'top1_prediction', 'match_rank', 'score']])\n",
    "\n",
    "# Calculate accuracy based on score == 3\n",
    "accuracy_bm = (prompt['score'] == 3).mean()\n",
    "\n",
    "print(f\"Top-1 Accuracy: {accuracy_bm:.2%}\")\n",
    "\n",
    "# Also show top-3 accuracy\n",
    "top3_accuracy_bm = prompt['in_top3'].mean()\n",
    "print(f\"Top-3 Accuracy: {top3_accuracy_bm:.2%}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#get unique tags in sorted order\n",
    "tags = sorted(set(prompt['desired_bird']))\n",
    "\n",
    "confusion = confusion_matrix(prompt['desired_bird'], prompt['top1_prediction'], labels=tags)\n",
    "\n",
    "#ploting the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "cax = ax.matshow(confusion, cmap=\"Blues\")\n",
    "plt.colorbar(cax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1: desired_bird = american robin, prediction = ['american robin', 'red-winged blackbird', 'house finch'], score = 3\n",
      "Row 2: desired_bird = bald eagle, prediction = ['bald eagle', 'golden eagle', 'california condor'], score = 3\n",
      "Row 3: desired_bird = buteos, prediction = ['red-tailed hawk', 'ferruginous hawk', 'northern harrier'], score = 0\n",
      "Row 4: desired_bird = prairie falcon, prediction = ['sharp-shinned hawk', \"cooper's hawk\", 'american kestrel'], score = 0\n",
      "Row 5: desired_bird = mourning dove, prediction = ['mourning dove', 'rock pigeon', 'eurasian collared-dove'], score = 3\n",
      "Row 6: desired_bird = house finch, prediction = ['house finch', \"cassin's finch\", 'purple finch'], score = 3\n",
      "Row 7: desired_bird = turkey vulture, prediction = ['turkey vulture', 'golden eagle', 'california condor'], score = 3\n",
      "Row 8: desired_bird = western bluebird, prediction = ['western bluebird', 'mountain bluebird', 'lazuli bunting'], score = 3\n",
      "Row 9: desired_bird = fox sparrow, prediction = ['common redpoll', 'pine siskin', 'american goldfinch'], score = 0\n",
      "Row 10: desired_bird = red-winged blackbird, prediction = ['red-winged blackbird', \"brewer's blackbird\", 'common raven'], score = 3\n",
      "Row 11: desired_bird = spotted towhee, prediction = ['american kestrel', 'northern flicker', \"lewis's woodpecker\"], score = 0\n",
      "Row 12: desired_bird = lesser scaup, prediction = ['lesser scaup', 'greater scaup', \"barrow's goldeneye\"], score = 3\n",
      "Row 13: desired_bird = cedar waxwing, prediction = ['american goldfinch', 'western tanager', 'yellow warbler'], score = 0\n",
      "Row 14: desired_bird = killdeer, prediction = ['house sparrow', 'white-crowned sparrow', 'vesper sparrow'], score = 0\n",
      "Row 15: desired_bird = wood duck, prediction = ['wood duck', 'harlequin duck', 'hooded merganser'], score = 3\n",
      "Row 16: desired_bird = mallard, prediction = ['mallard', 'gadwall', 'american wigeon'], score = 3\n",
      "Row 17: desired_bird = pygmy nuthatch, prediction = ['savannah sparrow', 'song sparrow', \"lincoln's sparrow\"], score = 0\n",
      "\n",
      "Total Score: 30\n",
      "Max Score: 102\n",
      "Accuracy: 29.411765\n"
     ]
    }
   ],
   "source": [
    "#get the gemini accuracy\n",
    "total_score = 0\n",
    "max_score = len(prompt) * 3\n",
    "num_rows = 0\n",
    "\n",
    "\n",
    "for index, row in prompt.iterrows():\n",
    "    desired_bird = row['desired_bird'].strip().lower()\n",
    "    predictions_raw = row['gemini_2.0_flash']\n",
    "    predictions = [p.strip().lower() for p in predictions_raw.split(',')]\n",
    "\n",
    "    score = 0\n",
    "    if len(predictions) >= 1 and desired_bird == predictions[0]:\n",
    "        score = 3\n",
    "    elif len(predictions) >= 2 and desired_bird == predictions[1]:\n",
    "        score = 2 \n",
    "    elif len(predictions) >= 3 and desired_bird == predictions[2]:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "\n",
    "    total_score += score\n",
    "    max_score += 3\n",
    "    num_rows += 1\n",
    "    print(f\"Row {num_rows}: desired_bird = {desired_bird}, prediction = {predictions}, score = {score}\")\n",
    "    \n",
    "accuracy = total_score / max_score if max_score > 0  else 0\n",
    "accuracy = accuracy * 100\n",
    "print(f\"\\nTotal Score: {total_score}\")\n",
    "print(f\"Max Score: {max_score}\")\n",
    "print(f\"Accuracy: {accuracy:2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
